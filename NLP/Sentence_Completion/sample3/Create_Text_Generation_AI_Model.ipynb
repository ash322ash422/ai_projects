{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ab6f1e5d-54b2-4861-a838-254991ab6b38",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ab6f1e5d-54b2-4861-a838-254991ab6b38"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pickle\n",
        "import heapq\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c8cdac11-c039-4bab-91c4-3e92e35a0ef4",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "c8cdac11-c039-4bab-91c4-3e92e35a0ef4"
      },
      "outputs": [],
      "source": [
        "text_df = pd.read_csv(\"/content/sample_data/fake_or_real_news.csv\")\n",
        "text = list(text_df.text.values)\n",
        "joined_text = \" \".join(text)\n",
        "\n",
        "with open(\"joined_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(joined_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5b37da10-c72c-49a6-83b3-91ed9504689d",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5b37da10-c72c-49a6-83b3-91ed9504689d"
      },
      "outputs": [],
      "source": [
        "partial_text = joined_text[:1000000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c8a12caf-9d1e-4916-8554-7b102cf2abfa",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "c8a12caf-9d1e-4916-8554-7b102cf2abfa"
      },
      "outputs": [],
      "source": [
        "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "tokens = tokenizer.tokenize(partial_text.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b351bd43-00b3-4421-b572-b633849b382c",
      "metadata": {
        "tags": [],
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "b351bd43-00b3-4421-b572-b633849b382c"
      },
      "outputs": [],
      "source": [
        "unique_tokens = np.unique(tokens)\n",
        "unique_token_index = {token: index for index, token in enumerate(unique_tokens)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4b4e1458-225e-4f44-8fa2-f462aa6087bb",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4b4e1458-225e-4f44-8fa2-f462aa6087bb"
      },
      "outputs": [],
      "source": [
        "n_words = 10\n",
        "input_words = []\n",
        "next_word = []\n",
        "\n",
        "for i in range(len(tokens) - n_words):\n",
        "    input_words.append(tokens[i:i + n_words])\n",
        "    next_word.append(tokens[i + n_words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "11b4ce79-9fa7-41a2-a71b-c0a2134b16aa",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "11b4ce79-9fa7-41a2-a71b-c0a2134b16aa"
      },
      "outputs": [],
      "source": [
        "X = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)  # for each sample, n input words and then a boolean for each possible next word\n",
        "y = np.zeros((len(next_word), len(unique_tokens)), dtype=bool)  # for each sample a boolean for each possible next word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "758caffb-288e-4c16-878d-f969fde3d081",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "758caffb-288e-4c16-878d-f969fde3d081"
      },
      "outputs": [],
      "source": [
        "for i, words in enumerate(input_words):\n",
        "    for j, word in enumerate(words):\n",
        "        X[i, j, unique_token_index[word]] = 1\n",
        "    y[i, unique_token_index[next_word[i]]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "89102ca3-b2fe-4a34-97c2-666164405ae8",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "89102ca3-b2fe-4a34-97c2-666164405ae8"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(unique_tokens)))\n",
        "model.add(Activation(\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "88ad45b0-b793-429a-80f7-105b04e086c2",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88ad45b0-b793-429a-80f7-105b04e086c2",
        "outputId": "1c75d167-84ad-4d72-ce13-523f54584ca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1326/1326 [==============================] - 169s 125ms/step - loss: 7.1234 - accuracy: 0.0706\n",
            "Epoch 2/10\n",
            "1326/1326 [==============================] - 161s 122ms/step - loss: 6.6974 - accuracy: 0.1032\n",
            "Epoch 3/10\n",
            "1326/1326 [==============================] - 161s 122ms/step - loss: 6.4814 - accuracy: 0.1214\n",
            "Epoch 4/10\n",
            "1326/1326 [==============================] - 161s 121ms/step - loss: 6.2867 - accuracy: 0.1343\n",
            "Epoch 5/10\n",
            "1326/1326 [==============================] - 160s 121ms/step - loss: 6.1101 - accuracy: 0.1477\n",
            "Epoch 6/10\n",
            "1326/1326 [==============================] - 160s 121ms/step - loss: 5.9397 - accuracy: 0.1606\n",
            "Epoch 7/10\n",
            "1326/1326 [==============================] - 160s 121ms/step - loss: 5.7764 - accuracy: 0.1741\n",
            "Epoch 8/10\n",
            "1326/1326 [==============================] - 161s 121ms/step - loss: 5.6138 - accuracy: 0.1870\n",
            "Epoch 9/10\n",
            "1326/1326 [==============================] - 161s 122ms/step - loss: 5.4528 - accuracy: 0.2007\n",
            "Epoch 10/10\n",
            "1326/1326 [==============================] - 161s 121ms/step - loss: 5.3004 - accuracy: 0.2145\n"
          ]
        }
      ],
      "source": [
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "history = model.fit(X, y, batch_size=128, epochs=10, shuffle=True).history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9be143d5-2869-4676-b347-eb09da09a821",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9be143d5-2869-4676-b347-eb09da09a821",
        "outputId": "75760c5a-7b52-4376-b24d-b9f50c927281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1326/1326 [==============================] - 421s 316ms/step - loss: 5.5365 - accuracy: 0.2450\n",
            "Epoch 2/5\n",
            "1326/1326 [==============================] - 428s 323ms/step - loss: 5.2118 - accuracy: 0.2751\n",
            "Epoch 3/5\n",
            "1326/1326 [==============================] - 426s 321ms/step - loss: 4.9456 - accuracy: 0.3037\n",
            "Epoch 4/5\n",
            "1326/1326 [==============================] - 427s 322ms/step - loss: 4.6771 - accuracy: 0.3346\n",
            "Epoch 5/5\n",
            "1326/1326 [==============================] - 426s 322ms/step - loss: 4.5058 - accuracy: 0.3530\n"
          ]
        }
      ],
      "source": [
        "# history = model.fit(X, y, batch_size=128, epochs=5, shuffle=True).history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c1a5e92e-9d96-4691-bcfa-39a777c868ab",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1a5e92e-9d96-4691-bcfa-39a777c868ab",
        "outputId": "073ef385-b622-4436-877f-6d4b12afad2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save(\"/content/sample_data/text_gen_model2.h5\")\n",
        "with open(\"history2.p\", \"wb\") as f:\n",
        "    pickle.dump(history, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "557f5ffa-e4d5-47fd-9f00-32b0b3e489ed",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "557f5ffa-e4d5-47fd-9f00-32b0b3e489ed"
      },
      "outputs": [],
      "source": [
        "model = load_model(\"/content/sample_data/text_gen_model2.h5\")\n",
        "history = pickle.load(open(\"history2.p\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0a1f478f-8e5e-4e82-bdc7-0b6620e5cadf",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0a1f478f-8e5e-4e82-bdc7-0b6620e5cadf"
      },
      "outputs": [],
      "source": [
        "def predict_next_word(input_text, n_best):\n",
        "    input_text = input_text.lower()\n",
        "    X = np.zeros((1, n_words, len(unique_tokens)))\n",
        "    for i, word in enumerate(input_text.split()):\n",
        "        X[0, i, unique_token_index[word]] = 1\n",
        "\n",
        "    predictions = model.predict(X)[0]\n",
        "    return np.argpartition(predictions, -n_best)[-n_best:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ba954451-6237-4d21-9e9d-81e23bcd6fab",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba954451-6237-4d21-9e9d-81e23bcd6fab",
        "outputId": "68eb645d-f8e4-43c1-f8fd-3421a7171575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 719ms/step\n"
          ]
        }
      ],
      "source": [
        "possible = predict_next_word(\"I will have to look into this thing because I\", 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "bfdef69f-618a-416c-a85c-51711adf86eb",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfdef69f-618a-416c-a85c-51711adf86eb",
        "outputId": "efa968b1-72f3-43eb-aa8a-f222c10d66d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "had\n",
            "don\n",
            "just\n",
            "think\n",
            "have\n"
          ]
        }
      ],
      "source": [
        "for idx in possible:\n",
        "    print(unique_tokens[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "30d8a2cb-90cc-4698-8418-76ec38384450",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "30d8a2cb-90cc-4698-8418-76ec38384450"
      },
      "outputs": [],
      "source": [
        "def generate_text(input_text, n_words, creativity=3):\n",
        "    word_sequence = input_text.split()\n",
        "    current = 0\n",
        "    for _ in range(n_words):\n",
        "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
        "        try:\n",
        "            choice = unique_tokens[random.choice(predict_next_word(sub_sequence, creativity))]\n",
        "        except:\n",
        "            choice = random.choice(unique_tokens)\n",
        "        word_sequence.append(choice)\n",
        "        current += 1\n",
        "    return \" \".join(word_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0c868ebb-be16-4d4f-84df-196d983e09c6",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0c868ebb-be16-4d4f-84df-196d983e09c6",
        "outputId": "b2e96910-999b-40e7-f898-dcbc44b34342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I will have to look into this thing because I just believe it they are the s why that the only thing is there that people will give what we would do all this will all your comment of the us family in america you don again can the same time of the future we said in america it means about the government it can do a path and has the they ve also long been more research at the polls were using it about two months ago he is a new republican candidate for her president she said there was a chance he will look a president of at'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "generate_text(\"I will have to look into this thing because I\", 100, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1327b41d-3b8b-4064-8d9f-782a7a07417a",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1327b41d-3b8b-4064-8d9f-782a7a07417a",
        "outputId": "93516546-21c8-4f33-9869-3758c196a00d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The president of the United States announced yesterday that he took from new mexico for american voters like bush leaders toward both candidates and it is doing with his support with their own support with all terrorist candidates in they see it on the rest of the people that will use it their terrorist program at government since they got by official now and their reported to u to keep her victory in a general country a few years to do all but he can be part at the time and i do not tell i was to help our support into this justice department said it are already close'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "generate_text(\"The president of the United States announced yesterday that he\", 100, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bd4036c-128d-4c4d-9d81-9584aa45b6b9",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4bd4036c-128d-4c4d-9d81-9584aa45b6b9",
        "outputId": "5e224bb6-5159-47b1-ca16-735056438caf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "american\n",
            "the\n",
            "our\n",
            "us\n",
            "president\n"
          ]
        }
      ],
      "source": [
        "for idx in predict_next_word(\"The president will most likely not be there to help\", 5):\n",
        "    print(unique_tokens[idx])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}